# main_sim.R
library(tidyverse)
library(data.table)
library(dbarts)
library(rstanarm)
library(lhs)
library(future.apply)
library(randtoolbox)
library(MCMCpack)
library(future)

# Source the configuration and function modules
source("sim/config.R")
source("sim/simulation_functions.R")
source("sim/optimisation_functions.R")
source("sim/gen_surface.R")


# Parse command-line arguments for n_trial
args <- commandArgs(trailingOnly = TRUE)
if (length(args) < 2) {
  stop("Please provide n_trial, n_subgroups as command-line arguments.")
}
n_trial <- as.numeric(args[1])
n_subgroups <- as.numeric(args[2])
workers <- 20
message(paste0(
  "Running simulation with n_trial = ",
  n_trial,
  ", n_subgroups = ",
  n_subgroups
))

log_dir <- file.path("sim/results", paste0("logs_subgroups_", n_subgroups))
if (!dir.exists(log_dir)) dir.create(log_dir, recursive = TRUE)


# Filenames (generated by setup_data.R)
external_file <- file.path(
  data_dir,
  paste0("external_ctrl_data_subg", n_subgroups, ".RDS")
)
trial_file <- file.path(
  data_dir,
  paste0("trial_data_subg", n_subgroups, ".RDS")
)

# Check that data exist
if (!file.exists(external_file) || !file.exists(trial_file)) {
  stop(
    "Data files for n_subgroups=",
    n_subgroups,
    " do not exist in data_dir. Please run setup_data.R first."
  )
}

# Load the fixed data
external_ctrl_data <- readRDS(external_file)
trial_data <- readRDS(trial_file)


control_prob <- plogis(control_outcome_logit(
  baseline_probs,
  age_grid,
  "non_linear_non_mon"
))
treatment_prob <- generate_probabilities(
  age_grid,
  baseline_probs,
  "non_linear_non_mon",
  "non_linear_mon_increase"
)

age_breaks <- create_age_breaks(age_grid, n_subgroups)
age_cuts <- cut(age_grid, breaks = age_breaks, right = FALSE)
age_groups <- levels(age_cuts)


subgroup_proportions <- gen_group_proportions(n_subgroups)
target_proportions <- rev(subgroup_proportions)


external_mod <- stan_glmer(
  outcome ~ 1 + (1 | age_group),
  data = external_ctrl_data,
  family = binomial(link = "logit"),
  prior = normal(0, 2.5),
  chains = 4,
  cores = 4,
  warmup = 1000,
  iter = 4000,
  seed = 123
)

# Extract posterior samples of the random intercepts
ctrl_post <- posterior_epred(
  external_mod,
  newdata = data.frame(trt = 0, age_group = age_groups)
)


# Calculate posterior mean control probabilities for each age group
ctrl_post_mean <- colMeans(ctrl_post)
names(ctrl_post_mean) <- age_groups


bhm_mod <- stan_glmer(
  outcome ~ (1 + trt | age_group),
  family = binomial,
  data = trial_data,
  warmup = 1000,
  iter = 4000,
  chains = 4,
  cores = 4,
  seed = 12345
)


posterior_samples <- as.matrix(bhm_mod)

# Select columns corresponding to treatment effects for each age group
treatment_effects <- posterior_samples %>%
  as.data.frame() %>%
  dplyr::select(starts_with("b[trt age_group")) %>%
  rename_with(~ gsub("b\\[trt age_group:", "", .x)) %>%
  rename_with(~ gsub("\\]", "", .x))

# Ensure the columns are in the same order as age_groups
treatment_effects <- treatment_effects[, age_groups]

# Convert to matrix
treatment_effects <- as.matrix(treatment_effects)

# Save intermediate outputs
saveRDS(ctrl_post, file = file.path(results_dir, "ctrl_probs.RDS"))
saveRDS(trial_data, file = file.path(results_dir, "trial_data.RDS"))
saveRDS(
  treatment_effects,
  file = file.path(results_dir, "treatment_effects.RDS")
)

# Convert log-odds ratios to odds ratios
OR_samples <- exp(treatment_effects)

# Compute odds for control group
odds_ctrl <- ctrl_post / (1 - ctrl_post) # Matrix of posterior samples x age groups

# Compute odds for treatment group
odds_trt <- odds_ctrl * OR_samples # Element-wise multiplication

# Compute treatment probabilities
trt_post <- odds_trt / (1 + odds_trt)


# assume the transition probability follows a step function over the age range
# we also run the STM long enough such that most of the population ends up in
# terminal state

# we already have:
# - 'age_breaks' as a numeric vector (e.g. c(40,48,56,65,73,81))
# - 'age_groups' as the resulting factor levels (e.g. "[40,48)" "[48,56)" "[56,65)" "[65,73)" "[73,81)")
# - 'ctrl_post' and 'trt_post' as matrices of posterior samples,
#   where columns correspond to these subgroups in order: age_groups

# We now want to expand these (step function) from ages 40 to 120

# Convert each integer age to the index of its subgroup
# 'include.lowest = TRUE' ensures the leftmost bin is used if it matches exactly
age_index <- cut(
  extended_age_grid,
  breaks = age_breaks,
  right = FALSE,
  labels = FALSE,
  include.lowest = TRUE
)

# Any age beyond the last cutpoint will yield NA. Assign them to the final subgroup.
age_index[is.na(age_index)] <- length(age_groups)

# Map these indices to the column indices of ctrl_post / trt_post
col_indices <- age_index

# Create matching column names for each row in 'all_ages'
col_names <- age_groups[col_indices]

# Expand the control posterior matrix
ctrl_post_all <- ctrl_post[, col_indices]
colnames(ctrl_post_all) <- col_names
names(dimnames(ctrl_post_all)) <- NULL

# Expand the treatment posterior matrix
trt_post_all <- trt_post[, col_indices]
colnames(trt_post_all) <- col_names
names(dimnames(trt_post_all)) <- NULL

# 'ctrl_post_all' and 'trt_post_all' now have 81 columns (for ages 40 to 120),

start_ages <- age_breaks[-(n_subgroups + 1)]


bhm_stm <- run_multi_cohort_sequential(
  start_ages = start_ages,
  ctrl_post_all,
  trt_post_all,
  n_cycles,
  c(utility_healthy, utility_diseased, utility_dead),
  c(cost_healthy, cost_diseased, cost_dead),
  cost_trt = c(
    cost_healthy + treatment_cost_per_cycle,
    cost_diseased,
    cost_dead
  ),
  wtp = 20000,
  extended_age_grid = extended_age_grid,
  n_target = n_target,
  age_groups = age_groups
)
Å“

bhm_stm_agg <- multi_cohort_average(bhm_stm, target_proportions)
INB_post <- (bhm_stm_agg$NB_trt - bhm_stm_agg$NB_ctrl) / n_target

saveRDS(INB_post, file = file.path(results_dir, "INB_post.RDS"))

################################################################################

# optimisation settings
# assume maxit for nelder-mead being 300, w/ n_init = 10;
# for random search, n_iter = 5000
# the future trial size n_trial = 500
# nb_samples: posterior of INB obtained from PSA
# eff_samples: posterior samples of treatment effect from the analysis
# aux_samples: external sourced baseline probabilities (used in trial generation)
# workers: 10 for Nelder-Mead as it runs sequentially; 25 for random search
# log_file: csv files for logging search results

# Define Log File Path
log_file <- file.path(log_dir, paste0("lhs_log_", n_trial, ".csv"))

optim_results <- adapt_rdn_search(
  niter = 4000,
  n_trial = n_trial,
  nb_samples = INB_post,
  eff_samples = treatment_effects,
  aux_samples = ctrl_post,
  age_groups = age_groups,
  workers = workers,
  log_file = log_file,
  method = "LHS"
)
saveRDS(
  optim_results,
  file = file.path(log_dir, paste0("results_lhs_", n_trial, ".RDS"))
)
message("Completed random search for n_trial = ", n_trial)
